{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import os\n",
    "from os import listdir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data from Local Files and Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# O is for Organic Foods \n",
    "# R is for Recyclable Foods\n",
    "\n",
    "# Connect to base directory of Project Data\n",
    "base_dir = 'C:/Users/umara/Desktop/Waste/DATASET'\n",
    "\n",
    "# Create a directory for our Training and Validation Images Data\n",
    "train_dir = os.path.join(base_dir, 'TRAIN')\n",
    "validation_dir = os.path.join(base_dir, 'TEST')\n",
    "content_dir = os.path.join(base_dir, 'content')\n",
    "\n",
    "# Directory with our training Organic/Recyclable pictures\n",
    "train_org_dir = os.path.join(train_dir, 'O')\n",
    "train_rec_dir = os.path.join(train_dir, 'R')\n",
    "\n",
    "# Directory with our validation/test Organic/Recyclable pictures\n",
    "test_org_dir = os.path.join(validation_dir, 'O')\n",
    "test_rec_dir = os.path.join(validation_dir, 'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training Organic item images : 12565\n",
      "total training Recylabe item images : 9999\n",
      "total validation Organic item images : 1401\n",
      "total validation Recylabe item images : 1112\n"
     ]
    }
   ],
   "source": [
    "# Lets check how much images there are in each test/train image files\n",
    "# There are a total of 22654 Training images and 2513 Test Images \n",
    "# Split up in 85% Train and 15% Test \n",
    "print('total training Organic item images :', len(os.listdir( train_org_dir )))\n",
    "print('total training Recylabe item images :', len(os.listdir( train_rec_dir )))\n",
    "\n",
    "print('total validation Organic item images :', len(os.listdir( test_org_dir ) ))\n",
    "print('total validation Recylabe item images :', len(os.listdir( test_rec_dir ) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our Neural Network Model\n",
    "Since we are facing a two-class classification problem, we will end our Neural Network with a 'sigmoid' activation parameter. This will give us a scalar between 0 and 1. Essentially the probability that our image is of Class 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # First Layer\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (150, 150, 3)),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    \n",
    "    # Second layer\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    \n",
    "    # Third Layer \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "\n",
    "    # Fourth Layer \n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    \n",
    "    # Final Layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the summary of our Neural Network and see how it is broken down by Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 15, 15, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,309,729\n",
      "Trainable params: 3,309,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Now we configure specfications on our Model\n",
    "\n",
    "We will use __Binary Cross Entropy__ for the loss function since its a Binary Classification Problem at hand and our final activation in our Neural Network is a Sigmoid. We are using the Metrics parameter to measure our accuracy of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(lr=0.01),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data\n",
    "\n",
    "This step allows for the images to be of the same width, height. Since data that goes into the CNN should be normalized we will normalize our pixels going from a range of [0, 255] to [0, 1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22564 images belonging to 2 classes.\n",
      "Found 2513 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Rescaling all images in given Dataset\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255.)\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# --------------------\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "# --------------------\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=15,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))     \n",
    "# --------------------\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "# --------------------\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=15,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 - 20s - loss: 30.0763 - accuracy: 0.5625 - val_loss: 0.6542 - val_accuracy: 0.5860\n",
      "Epoch 2/20\n",
      "100/100 - 21s - loss: 1.7065 - accuracy: 0.5355 - val_loss: 0.6869 - val_accuracy: 0.5570\n",
      "Epoch 3/20\n",
      "100/100 - 21s - loss: 0.9216 - accuracy: 0.5580 - val_loss: 0.6859 - val_accuracy: 0.5620\n",
      "Epoch 4/20\n",
      "100/100 - 20s - loss: 0.7408 - accuracy: 0.5565 - val_loss: 0.6845 - val_accuracy: 0.5650\n",
      "Epoch 5/20\n",
      "100/100 - 20s - loss: 1.1042 - accuracy: 0.5750 - val_loss: 0.6364 - val_accuracy: 0.6420\n",
      "Epoch 6/20\n",
      "100/100 - 20s - loss: 1.2157 - accuracy: 0.5735 - val_loss: 0.7351 - val_accuracy: 0.5630\n",
      "Epoch 7/20\n",
      "100/100 - 20s - loss: 0.7100 - accuracy: 0.6880 - val_loss: 0.5485 - val_accuracy: 0.7890\n",
      "Epoch 8/20\n",
      "100/100 - 20s - loss: 0.6145 - accuracy: 0.7525 - val_loss: 0.5508 - val_accuracy: 0.7250\n",
      "Epoch 9/20\n",
      "100/100 - 20s - loss: 0.5745 - accuracy: 0.7435 - val_loss: 0.4126 - val_accuracy: 0.8380\n",
      "Epoch 10/20\n",
      "100/100 - 20s - loss: 0.5427 - accuracy: 0.7685 - val_loss: 0.4441 - val_accuracy: 0.8290\n",
      "Epoch 11/20\n",
      "100/100 - 21s - loss: 0.5272 - accuracy: 0.7950 - val_loss: 0.4265 - val_accuracy: 0.8740\n",
      "Epoch 12/20\n",
      "100/100 - 22s - loss: 0.5295 - accuracy: 0.7820 - val_loss: 0.4280 - val_accuracy: 0.8150\n",
      "Epoch 13/20\n",
      "100/100 - 21s - loss: 0.5164 - accuracy: 0.7850 - val_loss: 0.4386 - val_accuracy: 0.8320\n",
      "Epoch 14/20\n",
      "100/100 - 19s - loss: 0.4708 - accuracy: 0.8005 - val_loss: 0.4521 - val_accuracy: 0.8040\n",
      "Epoch 15/20\n",
      "100/100 - 20s - loss: 0.5030 - accuracy: 0.7802 - val_loss: 0.3464 - val_accuracy: 0.8990\n",
      "Epoch 16/20\n",
      "100/100 - 20s - loss: 0.5125 - accuracy: 0.8065 - val_loss: 0.3560 - val_accuracy: 0.8630\n",
      "Epoch 17/20\n",
      "100/100 - 21s - loss: 0.5172 - accuracy: 0.7790 - val_loss: 0.5398 - val_accuracy: 0.7720\n",
      "Epoch 18/20\n",
      "100/100 - 21s - loss: 0.5149 - accuracy: 0.7885 - val_loss: 0.4159 - val_accuracy: 0.8110\n",
      "Epoch 19/20\n",
      "100/100 - 21s - loss: 0.5061 - accuracy: 0.7815 - val_loss: 0.3885 - val_accuracy: 0.8550\n",
      "Epoch 20/20\n",
      "100/100 - 19s - loss: 0.5434 - accuracy: 0.7760 - val_loss: 0.4207 - val_accuracy: 0.8550\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=80,\n",
    "                    epochs=20,\n",
    "                    validation_steps=50,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our model so we can integrate it into the Web Application\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on New Data\n",
    "We will ask user for new input and will classify whether it is Organic Waste or Recyclable. \n",
    "\n",
    "<font color = 'red'> The Downloaded file should be in same **DIRECTORY** or have to give **FULL PATH**</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O_12792.jpg is Organic Waste\n"
     ]
    }
   ],
   "source": [
    "file_name = 'O_12792.jpg'\n",
    "\n",
    "new_content = os.path.join(content_dir, file_name)\n",
    "img = image.load_img(new_content, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images, batch_size=10)\n",
    "\n",
    "if classes[0]>0:\n",
    "    print(file_name + ' is Recyclable')\n",
    "else:\n",
    "    print(file_name + ' is Organic Waste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
